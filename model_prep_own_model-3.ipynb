{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as k\n",
    "from tensorflow.keras.layers import Lambda, Cropping2D, Dense, GlobalAveragePooling2D, Flatten, ZeroPadding2D, Conv2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.99)\n",
    "gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataGenerator2 import DataGenerator2\n",
    "from NeptuneMonitor import NeptuneMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer to grayscale converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale_converter(x):\n",
    "    return (0.21 * x[:,:,:,:1]) + (0.72 * x[:,:,:,1:2]) + (0.07 * x[:,:,:,-1:])\n",
    "\n",
    "def saturation_converter(x):\n",
    "    hsv = tf.image.rgb_to_hsv(x)\n",
    "    return hsv[: , : , : , :1: ]\n",
    "    #return cv2.cvtColor(x, cv2.COLOR_RGB2HSV)[:,:,1]\n",
    "\n",
    "def resize_converter(x):\n",
    "    return tf.keras.backend.resize_images(x, height_factor=0.5, width_factor=0.5, data_format=\"channels_last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation - own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda(resize_converter, name='resize'),\n",
    "# Flatten(name='flatten'),\n",
    "\n",
    "model = Sequential([\n",
    "    Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3), name='normalize'),\n",
    "    Cropping2D(cropping=((65,25), (0,0)), name='cropping_65_25'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(24,(5,5), padding='valid', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(36,(5,5), padding='valid', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(48,(5,5), padding='valid', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64,(3,3), padding='valid', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64,(3,3), padding='valid', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='linear', name='dense-100'),\n",
    "    Dense(50, activation='linear', name='dense-50'),\n",
    "    Dense(10, activation='linear', name='dense-10'),\n",
    "    Dense(1, activation='linear', name='dense-1')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 120\n",
    "patience = 10\n",
    "batch_size = 32\n",
    "learn_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_generator = DataGenerator2('./my_data/', epochs=epochs, batch_size=batch_size, balance=False, debug=False)\n",
    "udacity_generator = DataGenerator2('./udacity_data/', epochs=epochs, batch_size=batch_size, balance=False, debug=False)\n",
    "my_generator.balance = True\n",
    "udacity_generator.balance = True\n",
    "generator = my_generator.merge(udacity_generator)\n",
    "\n",
    "train, valid = generator.split(factor = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainable_layers = None\n",
    "params = {'epochs': epochs, 'lr':learn_rate, 'batch_size':batch_size, 'trainable': trainable_layers, 'balanced_dataset': True}\n",
    "logger = NeptuneMonitor('own_nvidia', 'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vbmVwdHVuZS5pbnRpdmUub3JnIiwiYXBpX2tleSI6IjAzZmMyZjBlLWY2ODQtNDQ1Yi1hNjU5LTAwMjNmNTFhMDc0YyJ9', 'grzegorz.tyminski/Behavioral-Clonning', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.3, patience=patience, min_lr=1e-6, verbose=1)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=patience+1)\n",
    "fit_result = model.fit_generator(train,\n",
    "                                 steps_per_epoch=train.batches,\n",
    "                                 epochs=train.epochs,\n",
    "                                 verbose=1,\n",
    "                                 validation_data=valid,\n",
    "                                 validation_steps=valid.batches,\n",
    "                                 callbacks=[reduce_lr, early_stop, logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fit_result.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in enumerate(fit_result.history['loss']):\n",
    "    print(f\"EPOCH {i+1}:{v:0.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
